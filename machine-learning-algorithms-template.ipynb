{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template for Building Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a template of the code needed to create the main Machine Learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn import linear_model \n",
    "\n",
    "# Create training and test subsets\n",
    "x_train = train_dataset_predictor_variables\n",
    "y_train = train_dataset_predicted_variable\n",
    "\n",
    "x_test  = test_dataset_precictor_variables \n",
    "\n",
    "# Create linear regression object\n",
    "linear = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model with training data and check the score\n",
    "linear.fit(x_train, y_train)\n",
    "linear.score(x_train, y_train)\n",
    "\n",
    "# Collect coefficients\n",
    "print('Coefficient: \\n', linear.coef_)\n",
    "print('Intercept: \\n', linear.intercept_)\n",
    "\n",
    "# Make predictions\n",
    "predicted_values = linear.predict(x_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create training and test subsets\n",
    "x_train = train_dataset_predictor_variables\n",
    "y_train = train_dataset_predicted_variable\n",
    "\n",
    "x_test  = test_dataset_precictor_variables \n",
    "\n",
    "# Create logistic regression object\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model with training data and checking the score\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_train, y_train)\n",
    "\n",
    "# Collect coefficients\n",
    "print('Coefficient: \\n', modelo.coef_)\n",
    "print('Intercept: \\n', modelo.intercept_)\n",
    "\n",
    "# Make predictions\n",
    "valores_previstos = modelo.predict(x_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn import tree\n",
    "\n",
    "# Create training and test subsets\n",
    "x_train = train_dataset_predictor_variables\n",
    "y_train = train_dataset_predicted_variable\n",
    "\n",
    "x_test  = test_dataset_precictor_variables \n",
    "\n",
    "# Create Decision Tree Regressor Object\n",
    "model = tree.DecisionTreeRegressor() \n",
    "\n",
    "# Create Decision Tree Classifier Object\n",
    "model = tree.DecisionTreeClassifier() \n",
    "\n",
    "# Train the model with training data and checking the score\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predicted_values = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Create training and test subsets\n",
    "x_train = train_dataset_predictor_variables\n",
    "y_train = train_dataset_predicted variable\n",
    "\n",
    "x_test  = test_dataset_precictor_variables   \n",
    "\n",
    "# Create GaussianNB object\n",
    "model = GaussianNB() \n",
    "\n",
    "# Train the model with training data \n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predicted_values = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn import svm\n",
    "\n",
    "# Create training and test subsets\n",
    "x_train = train_dataset_predictor_variables\n",
    "y_train = train_dataset_predicted variable\n",
    "\n",
    "x_test  = test_dataset_precictor_variables  \n",
    "\n",
    "# Create SVM Classifier object  \n",
    "model = svm.svc()\n",
    "\n",
    "# Train the model with training data and checking the score\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predicted_values = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create training and test subsets\n",
    "x_train = train_dataset_predictor_variables\n",
    "y_train = train_dataset_predicted variable\n",
    "\n",
    "x_test  = test_dataset_precictor_variables \n",
    "\n",
    "# Create KNeighbors Classifier Objects  \n",
    "KNeighborsClassifier(n_neighbors = 6) # default value = 5\n",
    "\n",
    "# Train the model with training data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predicted_values = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create training and test subsets\n",
    "x_train = train_dataset_predictor_variables\n",
    "y_train = train_dataset_predicted variable\n",
    "\n",
    "x_test  = test_dataset_precictor_variables  \n",
    "\n",
    "# Create KMeans objects \n",
    "k_means = KMeans(n_clusters = 3, random_state = 0)\n",
    "\n",
    "# Train the model with training data\n",
    "model.fit(x_train)\n",
    "\n",
    "# Make predictions\n",
    "predicted_values = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create training and test subsets\n",
    "x_train = train_dataset_predictor_variables\n",
    "y_train = train_dataset_predicted variable\n",
    "\n",
    "x_test  = test_dataset_precictor_variables  \n",
    "\n",
    "# Create Random Forest Classifier objects \n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Train the model with training data \n",
    "model.fit(x_train, x_test)\n",
    "\n",
    "# Make predictions\n",
    "predicted_values = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn import decomposition\n",
    "\n",
    "# Create training and test subsets\n",
    "x_train = train_dataset_predictor_variables\n",
    "y_train = train_dataset_predicted variable\n",
    "\n",
    "x_test  = test_dataset_precictor_variables   \n",
    "\n",
    "# Creating PCA decomposition object\n",
    "pca = decomposition.PCA(n_components = k) \n",
    "\n",
    "# Creating Factor analysis decomposition object\n",
    "fa = decomposition.FactorAnalysis()\n",
    "\n",
    "# Reduc the size of the training set using PCA\n",
    "reduced_train = pca.fit_transform(train)\n",
    "\n",
    "# Reduce the size of the training set using PCA\n",
    "reduced_test = pca.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting & AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create training and test subsets\n",
    "x_train = train_dataset_predictor_variables\n",
    "y_train = train_dataset_predicted variable\n",
    "\n",
    "x_test  = test_dataset_precictor_variables  \n",
    "\n",
    "# Creating Gradient Boosting Classifier object\n",
    "model = GradientBoostingClassifier(n_estimators = 100, learning_rate = 1.0, max_depth = 1, random_state = 0)\n",
    "\n",
    "# Training the model with training data \n",
    "model.fit(x_train, x_test)\n",
    "\n",
    "# Make predictions\n",
    "predicted_values = model.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
